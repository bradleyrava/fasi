---
title: "Tutorial to the FASI Package in R"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial to the FASI Package in R}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r hide, echo=FALSE}

fasi <- function(observed_data, model_formula, split_p=0.5, alg="gam", class_label="y", niter_adaboost= 10) {

  ## Make sure the observed data set is a data frame
  observed_data <- as.data.frame(observed_data)

  ## Split the observed data into observed / calibrate by proportion split.
  obs_rows <- 1:nrow(observed_data)
  train_rows <- sample(obs_rows, split_p*length(obs_rows))
  calibrate_rows <- obs_rows[-train_rows]

  ## Create the train and calibrate data set from the splits above.
  train_data <- observed_data[train_rows,]
  calibrate_data <- observed_data[calibrate_rows,]

  ## For the model fit, separate the class label "y"
  y_train <- train_data[,which(colnames(train_data) == class_label)]
  train_data_noy <- train_data[,-which(colnames(train_data) == class_label)]

  ## GAM Fit
  if (alg == "gam") {
    ## For GAM, 0<=y<=1
    train_data_gam <- train_data
    train_data_gam$y <- as.factor(as.numeric(train_data_gam$y) - 1)
    ## Create the GAM fit
    model_fit <- gam::gam(model_formula, train_data_gam, family = "binomial")
  }
  ## Logistic Regression Fit
  else if (alg == "logit") {
    ## For logistic regression, 0<=y<=1
    train_data_logit <- train_data
    train_data_logit$y <- as.factor(as.numeric(train_data_logit$y) - 1)
    model_fit <- stats::glm(model_formula, data = train_data_logit, family = binomial)
  }
  ## Adaboost fit
  else if (alg == "adaboost") {
    dta_train_adaboost <- cbind.data.frame(data.matrix(train_data_noy), y = y_train)
    model_fit <- fastAdaboost::adaboost(model_formula, data=as.data.frame(dta_train_adaboost), nIter = niter_adaboost)
  }
  ## Nonparametric Naive Bayes
  else if (alg == "nonparametric_nb") {
    model_fit <- naivebayes::nonparametric_naive_bayes(x = data.matrix(train_data_noy), y = as.factor(y_train))
  }
  ## User provided their own ranking score model
  else if (alg == "user-provided") {
    model_fit <- NA
  }

  ## Combine the calibration and testing data with an indicator of which data set they were split into.
  train_indicator <- vector(mode="character", length = nrow(observed_data))
  train_indicator[train_rows] <- "train"
  train_indicator[calibrate_rows] <- "calibrate"
  observed_data_return <- cbind.data.frame(observed_data, train_indicator)

  ## Return the model fit, calibration data and testing data.
  return_object <- list(observed_data = observed_data_return,
                        model_fit = model_fit,
                        train_data = train_data,
                        calibrate_data = calibrate_data,
                        algorithm = alg)
  ## Specify the class of the return object
  class(return_object) <- "fasi"

  return(return_object)

}


predict.fasi <- function(fasi_object, test_data, alpha_1, alpha_2, rscore_plus=T, ptd_group_var="a", class_label="y",
                         ranking_score_calibrate, ranking_score_test, indecision_choice = "2", ...) {
  ######################
  ## Warning Messages ##
  ######################

  if (alpha_1 < 0 | alpha_1 > 1) {
    return(warning("alpha_1 must be a number between 0 and 1."))
  }
  if (alpha_2 < 0 | alpha_2 > 1) {
    return(warning("alpha_2 must be a number between 0 and 1."))
  }
  if (rscore_plus != T & rscore_plus != F) {
    return(warning("rscore_plus must be a logical. T/F."))
  }

  ######################

  ## Pull out the calibrate data
  calibrate_data <- fasi_object$calibrate_data

  ## Make sure the test data set is a data frame
  if (is.data.frame(test_data) == F) {
    test_data <- as.data.frame(test_data)
  }

  ## Preset the class 2 and class 2 label. Future iterations of the package will allow a user specified version.
  class_1_label = 1
  class_2_label = 2

  calibrate_data_withy <- fasi_object$calibrate_data
  calibrate_data_noy <- calibrate_data_withy[,-which(colnames(calibrate_data_withy)==class_label)]

  ## Use the model provided to estimate ranking scores
  model_fit <- fasi_object$model_fit

  ## GAM Fit
  if (fasi_object$algorithm == "gam") {
    ## Calibrate ranking scores
    logit_calibrate <- predict(model_fit, newdata = calibrate_data_noy)
    calibrate_data$s <- exp(logit_calibrate) / (1+exp(logit_calibrate))

    ## Testing ranking scores
    logit_test <- predict(model_fit, newdata = test_data)
    test_data$s <- exp(logit_test) / (1+exp(logit_test))
  }
  ## Logistic Regression Fit
  else if (fasi_object$algorithm == "logit") {
    ## Calibrate ranking scores
    logit_calibrate <- predict(model_fit, newdata = calibrate_data_noy)
    calibrate_data$s <- exp(logit_calibrate) / (1+exp(logit_calibrate))

    ## Testing ranking scores
    logit_test <- predict(model_fit, newdata = test_data)
    test_data$s <- exp(logit_test) / (1+exp(logit_test))
  }
  ## Adaboost fit
  else if (fasi_object$algorithm == "adaboost") {
    calibrate_data$s <- predict(model_fit, newdata = calibrate_data_noy)$prob[,2]
    test_data$s <- predict(model_fit, newdata = test_data)$prob[,2]
  }
  ## Nonparametric Naive Bayes
  else if (fasi_object$algorithm == "nonparametric_nb") {
    calibrate_data$s <- predict(model_fit, newdata = data.matrix(calibrate_data_noy), type = "prob")[,2]
    test_data$s <- predict(model_fit, newdata = data.matrix(test_data), type = "prob")[,2]
  }
  ## User provided their own ranking score model
  else if (fasi_object$algorithm == "user-provided") {
    calibrate_data <- fasi_object$observed_data

    calibrate_data$s <- ranking_score_calibrate
    test_data$s <- ranking_score_test
  }

  ## Subset the data on the information we need for the fasi algorithm. ##

  ## Important column's in the x_observed data frame. These are the same for the train and calibrate data set.
  ptd_group_col_cal <- which(colnames(calibrate_data) == ptd_group_var)
  class_label_col_cal <- which(colnames(calibrate_data) == class_label)
  rank_col_cal <- which(colnames(calibrate_data) == "s")

  ## Important column's in the x_test data frame.
  ptd_group_col_test <- which(colnames(test_data) == ptd_group_var)
  class_label_col_test <- which(colnames(test_data) == class_label)
  rank_col_test <- which(colnames(test_data) == "s")

  z_calibrate <- as.data.frame(calibrate_data[,c(class_label_col_cal, rank_col_cal, ptd_group_col_cal)])
  colnames(z_calibrate) <- c("y", "s", "a")
  z_test <- as.data.frame(test_data[,c(class_label_col_test, rank_col_test, ptd_group_col_test)])
  colnames(z_test) <- c("y", "s", "a")

  ## Determine the protected groups in the dataset.
  a_test_unique <- unique(z_test$a)

  ## Determine the class labels in the dataset.
  y_test_unique <- unique(z_test$y)
  if (sort(as.numeric(y_test_unique))[1] != 1 & sort(as.numeric(y_test_unique))[2] != 2) {
    return(warning("The class labels MUST be coded as 1 and 2. Please change your class label names to reflect this."))
  }
  class_1_label <- y_test_unique[which(y_test_unique != class_2_label)]

  ## Calculate the r-scores for every observation in the test data set.
  r_score2 <- sapply(1:nrow(z_test), function(ii) fasi::rscore(z_test$s[ii], class_2_label, z_test$a[ii], z_calibrate, z_test, rscore_plus, r2_indicator=T))
  r_score1 <- sapply(1:nrow(z_test), function(ii) fasi::rscore(z_test$s[ii], class_1_label, z_test$a[ii], z_calibrate, z_test, rscore_plus, r2_indicator=F))
  r_scores <- cbind.data.frame(r_score1, r_score2)

  ## Classify the observations according to the calculated r-scores (3-options)
  if (indecision_choice == "1") {
    classification_vector <- vector(mode="numeric", length = nrow(z_test))
    classification_vector[r_scores$r_score2 <= alpha_2] <- class_2_label
    classification_vector[r_scores$r_score1 <= alpha_1] <- class_1_label
  } else if (indecision_choice == "2") {
    classification_vector <- vector(mode="numeric", length = nrow(z_test))
    classification_vector[r_scores$r_score1 <= alpha_1] <- class_1_label
    classification_vector[r_scores$r_score2 <= alpha_2] <- class_2_label
  } else if (indecision_choice == "3") {
    classification_vector <- vector(mode="numeric", length = nrow(z_test))
    classification_vector[r_scores$r_score1 <= alpha_1] <- class_1_label
    classification_vector[r_scores$r_score2 <= alpha_2] <- class_2_label
    classification_vector[r_scores$r_score2 <= alpha_2 & r_scores$r_score1 <= alpha_1] <- 0
  } else {
    return(warning("Please use a valid indecision_choice (1-3)."))
  }

  return_object <- list(r_scores=r_scores,
                        classification=classification_vector,
                        rscore_plus=rscore_plus)

  class(return_object) <- "fasi"

  return(return_object)
}


rscore <- function(s_test_cur, y_class_cur, a_cur, z_cal, z_test, rscore_plus, r2_indicator) {
  n_a_cal <- length(which(z_cal$a == a_cur))
  m_a <- length(which(z_test$a == a_cur))

  if (r2_indicator == T) {
    ## Numerator of r-score
    z_cal_acur <- z_cal[which(z_cal$a == a_cur),]
    z_cal_acur_thresh <- z_cal_acur[which(z_cal$s >= s_test_cur),]
    z_cal_acur_thresh_new <- z_cal_acur_thresh[which(z_cal_acur_thresh$y != y_class_cur),]
    ## Denominator of r-score (includes z_cal_acur_thresh above)
    z_test_acur <- z_test[which(z_test$a == a_cur),]
    z_test_acur_thresh <- z_test_acur[which(z_test_acur$s >= s_test_cur),]

    ## Calculate the r-score or r-score+
    if (rscore_plus == T) {
      r_score_term <- ((1/(n_a_cal+1)) * (nrow(z_cal_acur_thresh_new) + 1)) / ((1/(m_a + n_a_cal + 1)) * (nrow(z_cal_acur_thresh) + nrow(z_test_acur_thresh) + 1))
      ## Technical adjustment: If the r-score is greater than 1, set it to 1.
      r_score_term <- ifelse(r_score_term > 1, 1, r_score_term)
    } else {
      r_score_term <- ((1/(n_a_cal+1)) * (nrow(z_cal_acur_thresh_new) + 1)) / ((1/(m_a)) * (nrow(z_test_acur_thresh)))
      ## Technical adjustment: If the r-score is greater than 1, set it to 1.
      r_score_term <- ifelse(r_score_term > 1, 1, r_score_term)
    }
  } else {
    ## Numerator of r-score
    z_cal_acur <- z_cal[which(z_cal$a == a_cur),]
    z_cal_acur_thresh <- z_cal_acur[which((1-z_cal$s) >= (1-s_test_cur)),]
    z_cal_acur_thresh_new <- z_cal_acur_thresh[which(z_cal_acur_thresh$y != y_class_cur),]
    ## Denominator of r-score (includes z_cal_acur_thresh above)
    z_test_acur <- z_test[which(z_test$a == a_cur),]
    z_test_acur_thresh <- z_test_acur[which((1-z_test_acur$s) >= (1-s_test_cur)),]

    ## Calculate the r-score or r-score+
    if (rscore_plus == T) {
      r_score_term <- ((1/(n_a_cal+1)) * (nrow(z_cal_acur_thresh_new) + 1)) / ((1/(m_a + n_a_cal + 1)) * (nrow(z_cal_acur_thresh) + nrow(z_test_acur_thresh) + 1))
      ## Technical adjustment: If the r-score is greater than 1, set it to 1.
      r_score_term <- ifelse(r_score_term > 1, 1, r_score_term)
    } else {
      r_score_term <- ((1/(n_a_cal+1)) * (nrow(z_cal_acur_thresh_new) + 1)) / ((1/(m_a)) * (nrow(z_test_acur_thresh)))
      ## Technical adjustment: If the r-score is greater than 1, set it to 1.
      r_score_term <- ifelse(r_score_term > 1, 1, r_score_term)

    }
  }

  return(r_score_term)
}
```
# Implementing the Fair Adjusted Selective Inference (FASI) procedure
  This is an R package for implementing the FASI method as described in the paper "A Fairness-Adjusted Selective Inference Framework ForClassification" by Bradley Rava, Wenguang Sun, Gareth M. James, and Xin Tong. 
  
# Introduction 
  
We consider a common classification setting where one wishes to make automated decisions for people from a variety of different protected groups. When controlling the overall false selection rate of a classifier, this error rate can unfairly be concentrated in one protected group instead of being evenly distributed among all of them. To address this, we develop a method called Fair Adjusted Selective Inference (FASI) that can simultaneously control the false selection rate for each protected group and the overall population at any user-specified level. This package is a user friendly way of implimenting the FASI algorithm.
  
This package will be extensively reworked soon. Please keep an eye out for version 2 when it is released. 
  
  
  
## What does the package do?
  
This R package implements the FASI procedure.
  
  
## How is the package structured?
  
The package has two main functions, "fasi" and "predict". They are both described below.

\textbf{fasi:} The fasi function is used to create a ranking score model model that will be used in the classification step. The inputs for this function are:
- observed_data: This is a data set of previous observations with their true classes. The fasi function will automatically split this data according to parameter split_p which the user will define.
- model_formula: Write a model formula that will be given to the ML model when creating the ranking scores. The choice of model will be user specified. 
- split_p: This is a number between 0 and 1 that determines the proportion of the observed data that should be reserved as the training data set. 
- alg: The user can specify their choice of ranking score algorithm here. The current choices are logistic regression "logit", Adaboost "adaboost", GAM "gam", nonparametric naive bayes "nonparametric_nb", and "user-provided". "user-provided" should only be used if you want to use an algorithm that the fasi function doesn't currently support. If you pick this option, the fasi function will create a simple fasi object that will need user provided ranking scores in the next step.
- class_label: What is the column name of your class label?
- niter_adaboost: If you pick adaboost, you can specify the number of weak learners. If you are not using adaboost, this parameter is meaningless. 

\textbf{predict:} The predict function should be used after the fasi function has been called. Even if you are specifying your own ranking scores! With a fasi_object, the predict function will estimate the r-scores for each observation in your test data set (new observations) and then classify each individual according to the specified thresholds. There are a few options the user can specify for how this is done.
- fasi_object: A fitted fasi object that can be obtained from the "fasi" function.
- test_data: A data set of new observations that you want to classify according to the fasi algorithm. 
- alpha_1: The desired overall and group-wise FSR control for class 1. This is a number between 0 and 1. 
- alpha_2: The desired overall and group-wise FSR control for class 2. This is a number between 0 and 1.   
- rscore_plus: There are two versions of the r-score that can be calculated. The r-score and r-score plus. They are described in depth in the paper. By default, the r-score plus is calculated. 
- ptd_group_var: What is the column name of your protected groups?
- class_label: What is the column name of your class label?
- ranking_score_calibrate: If you are not using a built in ML model from the fasi function, provide the ranking scores for the calibration data set here. 
- ranking_score_test: If you are not using a built in ML model from the fasi function, provide the ranking scores for the test data set here. 
- indecision_choice: It is possible that there will be conflicts with the r-scores i.e. we have an observation that we are confident in placing both into class 1 and class 2. There are 3 ways we can treat this observation. Pick "1" if you want to always assign this observation to class 1. Pick "2" if you always want to assign this observation to class 2. Pick "3" if you want to always assign this observation to the indecision class. 
  
# Installing the package
  
The FASI package is available on github and can be installed through the "devtools" package. 
  
```{r eval=FALSE}
library(devtools)
install_github("bradleyrava/fasi@master")
```

Once installed, you can load the package and functions into your R session with the following command

```{r message=FALSE, warning=FALSE, eval=FALSE}
library(fasi)
```

# Example

For guidance and reproducibility, this package includes the 2018 census data and compas algorithm data described in the paper. The original unedited versions can be found on ProPublica's github and at UCI's machine learning repository.  

https://github.com/propublica/compas-analysis/

https://archive.ics.uci.edu/ml/datasets/adult

Let's load the census data. 

```{r message=FALSE, warning=FALSE}
z <- fasi::adult
```

For this example, I will use logistic regression for computing the ranking scores.

Using the fasi package is easy. I will first randomly split my data into an observed and testing data set and then call the fasi function.

```{r}
obs_rows <- sample(1:nrow(z), 0.5*nrow(z))
test_rows <- (1:nrow(z))[-obs_rows]

observed_data <- z[obs_rows,]
test_data <- z[test_rows,]
```

Now that we have an observed and test data set, I will call the fasi function and specify that I want to use logistic regression. 

```{r}
model_formula <- as.formula("y ~ `hours-per-week`")
fasi_object <- fasi::fasi(observed_data = observed_data, model_formula = model_formula, alg = "logit")
```

The fasi object returns a lot of useful informaiton to us. Perhaps most importantly it gives us the model fit.

```{r}
fasi_object$model_fit
```

Let's now use the fasi object to classify the observations in our test data set. For this example, I will use alpha_1=alpha_2=0.1. In this data set, I will also use "sex" as the protected group. Since I did not change this variable name to "a", I will tell the predict function what the column name is. 

```{r}
fasi_predict <- predict(fasi_object = fasi_object, test_data = test_data, alpha_1 = 0.1, alpha_2 = 0.1, ptd_group_var = "sex")
head(fasi_predict$r_scores)
head(fasi_predict$classification)
```

That's it! You can use the r_scores / classifications directly.

If you wanted to provide your own ranking scores, you would only need to alter the process I described above slightly. For this example I will produce random ranking scores. However, you should strive to estimate better ones if you pick this approach!

```{r}
## Random ranking scores
calibrate_scores <- rnorm(nrow(observed_data))
test_scores <- rnorm(nrow(test_data))

fasi_object <- fasi(observed_data = observed_data, alg = "user-provided")
fasi_predict <- predict(fasi_object = fasi_object, test_data = test_data, alpha_1 = 0.1, alpha_2 = 0.1, ptd_group_var = "sex",
                        ranking_score_calibrate = calibrate_scores, ranking_score_test = test_scores)

```

## Future work
This package is currently a proof of concept and it can be useful for practicioners looking to quickly impliment the fasi procedure. In version 2, this pacakge will be much faster and it will allow for a cross validation method that will eliminate the need for a training / calibration testing data set. It will also offer more diagnostic / plotting tools.

Please let me know if there is any functionality you would like to see added to version 2. 


# Further questions or comments?

If you have any questions about this package or notice any bugs, please feel free to email Bradley Rava at brava@usc.edu 
